<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Noah Greifer" />

<meta name="date" content="2018-02-19" />

<title>Covariate Balance Tables and Plots: A Guide to the cobalt Package</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Covariate Balance Tables and Plots: A Guide to the cobalt Package</h1>
<h4 class="author"><em>Noah Greifer</em></h4>
<h4 class="date"><em>2018-02-19</em></h4>



<p>This is an introductory guide for the use of <code>cobalt</code> in most common scenarios. Two appendices are available for its use with more complicated data scenarios.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Preprocessing data through matching, weighting, or subclassification can be an effective way to reduce model dependence and improve efficiency when estimating the causal effect of a treatment (Ho, Imai, King, &amp; Stuart, 2007). Propensity scores and other related methods (e.g., coarsened exact matching, Mahalanobis distance matching, genetic matching) have become popular in the social and health sciences as tools for this purpose. Two excellent introductions to propensity scores and other preprocessing methods are Stuart (2010) and Austin (2011), which describe them simply and clearly and point to other sources of knowledge. The logic and theory behind preprocessing will not be discussed here, and reader’s knowledge of the causal assumption of strong ignorability is assumed.</p>
<p>Several packages in R exist to perform preprocessing and causal effect estimation, and some were reviewed by Keller &amp; Tipton (2016). Of primary note are <code>MatchIt</code> (Ho, Imai, King, &amp; Stuart, 2011), <code>twang</code> (Ridgeway, McCaffrey, Morral, Burgette, &amp; Griffin, 2016), <code>Matching</code> (Sekhon, 2011), <code>optmatch</code> (Hansen &amp; Klopfer, 2006), <code>CBPS</code> (Fong, Ratkovic, Hazlett, Yang, &amp; Imai, 2016), <code>ebal</code> (Hainmueller, 2014) and <code>WeightIt</code> (Greifer, 2017); these together provide a near complete set of preprocessing tools in R to date.</p>
<p>The following are the basic steps in performing a causal analysis using data preprocessing (Stuart, 2010):</p>
<ol style="list-style-type: decimal">
<li>Decide on covariates for which balance must be achieved</li>
<li>Estimate the distance measure (e.g., propensity score)</li>
<li>Condition on the distance measure (e.g., using matching, weighting, or subclassification)</li>
<li>Assess balance on the covariates of interest; if poor, repeat steps 2-4</li>
<li>Estimate the treatment effect in the conditioned sample</li>
</ol>
<p>Steps 2, 3, and 4 are accomplished by all of the packages mentioned above. However, Step 4, assessing balance, is often overlooked in propensity score applications, with researchers failing to report the degree of covariate balance achieved by their conditioning (Thoemmes &amp; Kim, 2011). Achieving balance is the very purpose of preprocessing because covariate balance is what justifies ignorability on the observed covariates, allowing for the potential for a valid causal inference after effect estimation (Ho et al., 2007).</p>
<p>In addition to simply achieving balance, researchers must also report balance to convince readers that their analysis was performed adequately and that their causal conclusions are valid (Thoemmes &amp; Kim, 2011). Covariate balance is typically assessed and reported by using statistical measures, including standardized mean differences, variance ratios, and t-test or Kolmogorov-Smirnov-test p-values. Balance can be reported in an article by means of balance tables or plots displaying the balance measures before and after conditioning. If a defensible measure of balance is used and presented, readers are empowered to judge for themselves whether the causal claim made is valid or not based on the methods used and covariates chosen.</p>
<p><code>cobalt</code> is meant to supplement or replace the balance assessment tools in the above packages and allow researchers to assess and report balance on covariates simply, clearly, and flexibly before and after conditioning. It integrates seamlessly with the above packages so that users can employ both the conditioning package of their choice and <code>cobalt</code> in conjunction to assess and report balance. It is important to note that <code>cobalt</code> does not replace the highly sophisticated <em>conditioning</em> tools of these packages, as it does no conditioning or estimation of its own.</p>
<p>The rest of this guide explains how to use <code>cobalt</code> with the above packages and others, as well as the choices instituted by the functions and customizable by the user.</p>
<div id="citing-cobalt" class="section level3">
<h3>Citing <code>cobalt</code></h3>
<p>When using <code>cobalt</code>, please cite your use of it along with the conditioning package used. The full APA reference for <code>cobalt</code> is the following:</p>
<p>Greifer, N. (2018). cobalt: Covariate Balance Tables and Plots. R package version 3.2.0.</p>
<p>For example, if you use <code>Matching</code> for propensity score estimation and matching and <code>cobalt</code> for balance assessment and/or reporting, a possible citation might go as follows:</p>
<blockquote>
<p>Matching was performed using the Matching package (Sekhon, 2011), and covariate balance was assessed using cobalt (Greifer, 2018), both in R (R Core Team, 2017).</p>
</blockquote>
</div>
</div>
<div id="why-cobalt" class="section level1">
<h1>Why <code>cobalt</code>?</h1>
<p>If most of the major conditioning packages contain functions to assess balance, why use <code>cobalt</code> at all? <code>cobalt</code> arose out of several desiderata when using these packages: to have standardized measures that were consistent across all conditioning packages, to allow for flexibility in the calculation and display of balance measures, and to incorporate recent methodological recommendations in the assessment of balance. However, some users of these packages may be completely satisfied with their capabilities and comfortable with their output; for them, <code>cobalt</code> still has value in its unique plotting capabilities that make use of <code>ggplot2</code> in R.</p>
<p>The following are some reasons why <code>cobalt</code> may be attractive to users of <code>MatchIt</code>, <code>twang</code>, <code>Matching</code>, <code>optmatch</code>, <code>CBPS</code>, <code>ebal</code>, and <code>WeightIt</code>:</p>
<div id="visual-clarity" class="section level3">
<h3>Visual clarity</h3>
<p><code>cobalt</code> presents one table in its balance output, and it contains all the information required to assess balance. <code>twang</code> and <code>CBPS</code> present two tables, <code>MatchIt</code> presents three tables, and <code>Matching</code> presents as many tables as there are covariates. Although each of these tables contains valuable information, the <code>bal.tab()</code> function in <code>cobalt</code> allows for a quick and easy search for the information desired, which is often a single column containing a balance statistic (such as the standardized mean difference) for the adjusted sample.</p>
</div>
<div id="useful-summaries" class="section level3">
<h3>Useful summaries</h3>
<p>Although a thorough balance assessment requires examining the balance of each covariate individually, <code>cobalt</code>’s <code>bal.tab()</code> function can also produce quick balance summaries that can aid in model selection when there are many covariates or higher order terms to examine. These summaries include the proportion of covariates that have met a user-specified threshold for balance and the covariate with the highest degree of imbalance, two values that have been shown to be effective in diagnosing imbalance and potential bias (Stuart, Lee, &amp; Leacy, 2013).</p>
</div>
<div id="one-tool-to-rule-them-all" class="section level3">
<h3>One tool to rule them all</h3>
<p>Because there is no <em>a priori</em> way to know which conditioning method will work best for a given sample, users should try several methods, and these methods are spread across various packages; for example, full matching is available only in <code>MatchIt</code> and <code>optmatch</code>, generalized boosted modeling only in <code>twang</code>, covariate balancing propensity score weighting only in <code>CBPS</code>, genetic matching only in <code>MatchIt</code> and <code>Matching</code>, and entropy balancing only in <code>ebal</code><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. If a user wants to compare these methods on their ability to generate balance in the sample, they cannot do so on the same metrics and with the same output. Each package computes balance statistics differently (if at all), and the relevant balance measures are in different places in each package. By using <code>cobalt</code> to assess balance across packages, users can be sure they are using a single, equivalent balance metric across methods, and the relevant balance statistics will be in the same place and computed the same way regardless of the conditioning package used.</p>
</div>
<div id="flexibility" class="section level3">
<h3>Flexibility</h3>
<p><code>cobalt</code> gives users choice in which statistics are presented and how they are calculated, but intelligently uses defaults that are in line with the goals of unified balance assessment and with the data available. Rather than displaying all values calculated, <code>bal.tab()</code> only displays what the user wants; at a bare minimum, the standardized mean difference for each covariate is displayed, which is traditionally considered sufficient for model selection and justification in preprocessing analysis for binary treatments. Even if the user doesn’t want other values displayed, they are all still calculated, and thus available for use in programming (though this can be disabled for increased speed).</p>
</div>
<div id="pretty-plots" class="section level3">
<h3>Pretty plots</h3>
<p>The main conditioning packages produce plots that can be useful in assessing balance, summarizing balance, and understanding the intricacies of the conditioning method for which simple text would be insufficient. Many of these plots are unique to each package, and <code>cobalt</code> has not attempted to replace or replicate them. For other plots, though, <code>cobalt</code> uses <code>ggplot2</code> to present clean, clear, customizable, and high-quality displays for balance assessment and presentation. The two included plotting functions are <code>bal.plot()</code>, which generates plots of the distributions of covariates and treatment levels so that more complete distributional balance can be assessed beyond numerical summaries, and <code>love.plot()</code>, which generates a plot summarizing covariate balance before and after conditioning, popularized by Dr. Thomas E. Love. Because these plots use <code>ggplot2</code> as their base, users familiar with <code>ggplot2</code> can customize various elements of the plots for use in publications or presentations.</p>
</div>
<div id="unique-features" class="section level3">
<h3>Unique features</h3>
<p>There are unique features in <code>cobalt</code> that do not exist in any other package. These include the handling of clustered and grouped data and the handling of data generated with multiple imputation. These more advanced uses of <code>cobalt</code> are described in detail in the accompanying Appendix 2. In addition, <code>cobalt</code> includes tools for handling data sets with continuous and multinomial treatments.</p>
</div>
</div>
<div id="how-to-use-cobalt" class="section level1">
<h1>How To Use cobalt</h1>
<p>There are three main functions for use in <code>cobalt</code>: <code>bal.tab()</code>, <code>bal.plot()</code>, and <code>love.plot()</code>. There are also several utility functions which can be used to ease the use of <code>cobalt</code> and other packages. The next sections describe how to use each, complete with example code and output. To start, install and load <code>cobalt</code> with the following code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## install.packages(&quot;cobalt&quot;)
<span class="kw">library</span>(<span class="st">&quot;cobalt&quot;</span>)</code></pre></div>
<div id="utilities" class="section level3">
<h3>Utilities</h3>
<p>In addition to its main functions, <code>cobalt</code> contains several utility functions, which include <code>f.build()</code>, <code>splitfactor()</code> and <code>unsplitfactor()</code>, and <code>get.w()</code>. These are meant to reduce the typing and programming burden that often accompany the use of R with a diverse set of packages. To simplify this vignette, decriptions of these functions are in Appendix 1. To understand the code in this vignette, you should be aware of <code>f.build()</code>, which creates a formula from its inputs, and <code>get.w()</code> which extracts weights from its input.</p>
</div>
<div id="bal.tab" class="section level2">
<h2><code>bal.tab()</code></h2>
<p><code>bal.tab()</code> is the primary function of <code>cobalt</code>. It produces balance tables for the objects given as inputs. The balance tables can be customized with a variety of inputs, which affect both calculation and presentation of values. It performs similar functions to <code>summary()</code> in <code>MatchIt</code>; <code>bal.table()</code>, <code>summary()</code>, and <code>dx.wts()</code> in <code>twang</code>; <code>MatchBalance()</code> and <code>summary()</code> in <code>Matching</code>; and <code>balance()</code> in <code>CBPS</code>. It can be seen as a replacement or a supplement to these functions.</p>
<p>For more help using <code>bal.tab()</code>, see <code>?bal.tab</code> in R, which contains information on how certain values are calculated and links to the help files for the <code>bal.tab()</code> methods that integrate with the above packages.</p>
<p>For simplicity, the description of the use of <code>bal.tab()</code> will be most complete in its use without any other package. The demonstration will display <code>bal.tab()</code>’s many options, several of which differ based on with which package, if any, <code>bal.tab()</code> is used. The other demonstrations will be minimal, highlighting how to use <code>bal.tab()</code> effectively with <code>MatchIt</code> and <code>WeightIt</code>, but not detailing all its possible options with these packages, to avoid redundancy. The use of <code>bal.tab()</code> with other packages is described in the accompanying Appendix 1, “Using cobalt with Other Preprocessing Packages”.</p>
<div id="using-bal.tab-on-its-own" class="section level3">
<h3>Using <code>bal.tab()</code> on its own</h3>
<p><code>bal.tab()</code> can take in any data set and set of weights, subclasses, or matching strata and evaluate balance on them. This can be useful if propensity score weights, subclasses, or matching strata were generated outside of the supported packages, if balance assessment is desired prior to adjustment, or if package output is adjusted in such a way as to make it unusable with one of <code>bal.tab()</code>’s other methods (e.g., if cases were manually removed or weights manually changed). In <code>twang</code>, the function <code>dx.wts()</code> performs a similar action by allowing for the balance assessment of groups weighted not using GBM, but it does not provide support for matching strata (e.g., those generated from <code>optmatch</code>) or subclasses. Below is an example of the use of <code>bal.tab()</code> with ATT weights generating using logistic regression for a weighting-by-the-odds analysis:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;lalonde&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;cobalt&quot;</span>) <span class="co">#If not yet loaded</span>
covs0 &lt;-<span class="st"> </span><span class="kw">subset</span>(lalonde, <span class="dt">select =</span> <span class="op">-</span><span class="kw">c</span>(treat, re78, nodegree, married))

<span class="co"># Generating ATT weights as specified in Austin (2011)</span>
lalonde<span class="op">$</span>p.score &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, 
                       <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)<span class="op">$</span>fitted.values
lalonde<span class="op">$</span>att.weights &lt;-<span class="st"> </span><span class="kw">with</span>(lalonde, treat <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>treat)<span class="op">*</span>p.score<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>p.score))

<span class="kw">bal.tab</span>(covs0, <span class="dt">treat =</span> lalonde<span class="op">$</span>treat, <span class="dt">weights =</span> lalonde<span class="op">$</span>att.weights,
        <span class="dt">method =</span> <span class="st">&quot;weighting&quot;</span>)</code></pre></div>
<p>Displayed first is the balance table, and last is a summary of sample size information. Because weighting was specified as the method used, effective sample sizes are given, as is done in <code>twang</code>. See the <code>twang</code> documentation, <code>?bal.tab</code>, or “Details on Calculations” below for details on this calculation.</p>
<p>There are several ways to specify input to <code>bal.tab()</code> when using data outside a conditioning package. The first, as shown above, is to use a data frame of covariates and vectors for treatment status and weights or subclasses. The user can additionally specify a vector of distance measures (e.g., propensity scores) if balance is to be assessed on those as well. If <code>weights</code> is left empty, balance on the unadjusted sample will be reported. The user can also optionally specify a data set to the <code>data</code> argument; this makes it so that the arguments to <code>treat</code>, <code>weights</code>, <code>distance</code>, <code>subclass</code>, and others can be specified either with a vector or with the name of a variable in the argument to <code>data</code> that contains the respective values.</p>
<p>Another way to specify input to <code>bal.tab()</code> is to use the formula interface. Below is an example of its use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, <span class="dt">weights =</span> <span class="st">&quot;att.weights&quot;</span>,
        <span class="dt">distance =</span> <span class="st">&quot;p.score&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;weighting&quot;</span>)</code></pre></div>
<p>To use the formula interface, the user must specify a formula relating treatment to the covariates for which balance is to be assessed <strong>and</strong> the data set where the elements of the formula can be found. Here, <code>f.build()</code> was used for simplicity, but the traditional formula input of <code>treat ~ v1 + v2 + v3 + ...</code> is also acceptible. As above, the arguments to <code>weights</code>, <code>distance</code>, <code>subclass</code>, and others can be specified either as vectors or data frames containing the values or as names of the variables in the argument to <code>data</code> containing the values. In the above example, an argument to <code>distance</code> was specified, and balance measures for the propensity score now appear in the balance table.</p>
<p>An argument to <code>method</code> must be specified for <code>bal.tab()</code> to process the data correctly. If left empty, weighting will be assumed, but a warning will appear. <code>&quot;matching&quot;</code> and <code>&quot;subclassification&quot;</code> are also allowed, and can be abbreviated. If no weights or subclasses are provided (i.e., to examine balance without preprocessing), no argument to <code>method</code> is required.</p>
<p>By default, <code>bal.tab()</code> outputs standardized mean differences for continuous variables and raw differences in proportion for binary variables. For more details on how these values are computed and determined, see <code>?bal.tab</code> or “Details on Calculations” below. To see raw or standardized mean differences for binary or continuous variables, you can manually set <code>binary</code> and/or <code>continuous</code> to <code>&quot;raw&quot;</code> or <code>&quot;std&quot;</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, <span class="dt">weights =</span> <span class="st">&quot;att.weights&quot;</span>,
        <span class="dt">method =</span> <span class="st">&quot;weighting&quot;</span>, <span class="dt">binary =</span> <span class="st">&quot;std&quot;</span>, <span class="dt">continuous =</span> <span class="st">&quot;std&quot;</span>)</code></pre></div>
<p>Users can specify additional variables for which to display balance using the argument to <code>addl</code>. Users can also add all squared terms and two-way interactions between covariates, including those in <code>addl</code>, by specifying <code>int = TRUE</code>. Interactions will not be computed for the distance measure (i.e., the propensity score), and squared terms will not be computed for binary variables. For more details on interactions, see “Details on Calculations”, below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Balance on all covariates in data set, including interactions and squares</span>
<span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, <span class="dt">weights =</span> <span class="st">&quot;att.weights&quot;</span>,
        <span class="dt">method =</span> <span class="st">&quot;weighting&quot;</span>, <span class="dt">addl =</span> <span class="kw">c</span>(<span class="st">&quot;nodegree&quot;</span>, <span class="st">&quot;married&quot;</span>), <span class="dt">int =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>Standardized mean differences can be computed several ways, and the user can decide how <code>bal.tab()</code> does so using the argument to <code>s.d.denom</code>, which controls whether the measure of spread in the denominator is the standard deviation of the treated group (<code>&quot;treated&quot;</code>), most apprpriate when computing the ATT; the standard deviation of the control group (<code>&quot;control&quot;</code>), most appropriate when computing the ATC; or the pooled standard deviation (<code>&quot;pooled&quot;</code>), computed as in Austin (2009, p. 3087), most appropriate when computing the ATE. If using weights for weighted analysis, <code>bal.tab()</code> can determine if the ATT or ATC are being estimated and supply <code>s.d.denom</code> accordingly. Otherwise, the default is <code>&quot;pooled&quot;</code>, and when matching or subclassification are used, the default is <code>&quot;treated&quot;</code>. See Austin (2011) for an explanation on how to calculate weights for estimation of the ATT, ATE, and ATC.</p>
<p>The next options only affect display, not the calculation of any statistics. First is <code>disp.means</code>, which controls whether the group means for each covariate are displayed in addition to the mean differences. This can be useful in reporting balance for publication, but in balance assessment mean differences are typically more useful.</p>
<p>Next is <code>disp.v.ratio</code>, which controls whether variance ratios are displayed, in addition to mean differences. Variance ratios are another important tool for assessing balance beyond mean differences because they pertain to the shape of the covariate distributions beyond their centers. Variance ratios close to 1 (i.e., equal variances in both groups) are indicative of group balance (Austin, 2009).</p>
<p>Next is <code>disp.ks</code>, which controls whether Kolmogorov-Smirnov (KS) statistics are displayed. KS statistics measure the greatest distance between the emiprical cumulative dsitribution functions (ECDFs) for each variable between two groups. The statistic is bounded at 0 and 1, with 0 indicting perfectly identical distributions and 1 indicating perfect seperation between the distributions (i.e., no overlap at all); values close to 0 are thus indicative of balance. The use of the KS statistic to formally assess balance is debated. Intutively, it makes sense to use it to diagnose balance because the interpretation and computation of the statistics are directly related to balance. Austin &amp; Stuart (2015) recommend its use, and it or a variant appears as a default balance statistic in <code>MatchIt</code>, <code>twang</code>, and <code>Matching</code>. On the other hand, Belitser et al. (2011), Stuart et al. (2013), and Ali et al. (2014) all found that global balance assessments using the KS statistic performed uniformly worse than standardized mean differences, esepcially at sample sizes less than 1000 in their simulations.</p>
<p>Next is <code>un</code>, which controls whether the statistics to be displayed should be displayed for the unadjusted group as well. This can be useful the first time balance is assessed to see the initial group imbalance. Setting <code>un = FALSE</code>, which is the default, can declutter the output to maintain the spotlight on the group balance after adjustment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Balance tables with variance ratios and statistics for the unadjusted sample</span>
<span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, <span class="dt">weights =</span> <span class="st">&quot;att.weights&quot;</span>,
        <span class="dt">method =</span> <span class="st">&quot;weighting&quot;</span>, <span class="dt">disp.v.ratio =</span> <span class="ot">TRUE</span>, <span class="dt">un =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>Finally, the user can specify a threshold for balance for mean differences, variance ratios, and KS statistics through the arguments to <code>m.threshold</code>, <code>v.threshold</code>, and <code>ks.threshold</code>. Thresholds can be useful in determining whether satisfactory balance has been achieved. For standardized mean differences, thresholds of .1 and .25 have been proposed, but Stuart et al. (2013) found that a threshold of .1 was more effective at assessing imbalance that would lead to biased effect estimation. In general, standardized mean differences should be as close to 0 as possible, but a conservative upper limit such as .1 can be a valuable heuristic in selecting models and defending the conditioning choice.</p>
<p>When <code>m.threshold</code> is specified, a few components are added to the balance output: an extra column in the balance table stating whether each covariate is or is not balanced according to the threshold; an extra table below the balance table with a tally of how many covariates are or are not balanced according to the threshold; and a notice of which covariate has the greatest imbalance after conditioning and whether it exceeded the threshold. Using a threshold for the mean difference implies that the differences are standardized (at least for continuous variables), because the threshold is meant to be scale invariant, which standardized mean differences are.</p>
<p>The argument to <code>v.threshold</code> determines the threshold for variance ratios that are acceptable for balance. Variance ratios are calculated in <code>cobalt</code> such that the greater variance is in the numerator, so they will always be greater than or equal to 1. Variance ratios close to 1 are indicative of good balance, but ratios as large as 2 may be acceptable (Rubin, 2001). When <code>v.threshold</code> is specified, the same additional output is created as above, except in evaluation of variance ratios. Because variance ratios are not displayed in the balance table by default, specifying <code>v.threshold</code> will also display variance ratios in the table.</p>
<p>When <code>ks.threshold</code> is specified, the same additional output is created as above, except in evaluation of KS statistics. Because KS statistics are not displayed in the balance table by default, specifying <code>ks.threshold</code> will also display KS statistics in the table. The value provided to <code>ks.threshold</code> should be between 0 and 1. Though no research has been done on acceptible thresholds for the KS statistics, we recommend seeking values less than 0.05 for continuous variables, which roughly corresponds to the KS statistic computed for two normally distributed samples wih a standardized mean difference of 0.1. For binary variables, KS statistics are not produced because they are equal to the raw difference in proportion.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Balance tables with thresholds for mean differences and variance ratios</span>
<span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, <span class="dt">weights =</span> <span class="st">&quot;att.weights&quot;</span>,
        <span class="dt">method =</span> <span class="st">&quot;weighting&quot;</span>, <span class="dt">m.threshold =</span> .<span class="dv">1</span>, <span class="dt">v.threshold =</span> <span class="dv">2</span>)</code></pre></div>
<p>To simplify output when many covariates are included or when <code>int = TRUE</code> is specified, <code>imbalanced.only</code> can be set to <code>TRUE</code>, which will only reveal imbalanced covariates in the output. These rae covariates that have failed to meet any of the balance thresholds set. In addition, <code>disp.bal.tab</code> can be set <code>TRUE</code>, which will hide the balance table (revealing only the balance summaries accompanying the threshold).</p>
<p>If sampling weights are used and are to be applied to both the adjusted and unadjusted groups, they can be specified with an argument to <code>s.weights</code>, which can be specified either by providing a vector of sampling weights for each unit or by providing the name of a variable in <code>data</code> containing the sampling weights. The adjusted and unadjusted samples will each be weighted by the sampling weights by multiplying the adjustment weights (if any) by the sampling weights.</p>
<p>It is possible to view balance for more than one set of weights at a time. The input to <code>weights</code> should be either the names of variables in <code>data</code> containing the desired weights or a named data frame containing each set of weights. The arguments to <code>method</code> and <code>s.d.denom</code> or <code>estimand</code> must have the same length as the number of sets of weights, or else be of length 1, applying the sole input to all sets of weights. Below is an example comparing the weights estimated above to a new set of weights. Another example can be found in the section “Comparing Balancing Methods”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generating ATT weights with different covariates</span>
lalonde<span class="op">$</span>p.score2 &lt;-<span class="st"> </span><span class="kw">glm</span>(treat <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(age<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>educ <span class="op">+</span><span class="st"> </span>re74, 
                        <span class="dt">data =</span> lalonde, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)<span class="op">$</span>fitted.values
lalonde<span class="op">$</span>att.weights2 &lt;-<span class="st"> </span><span class="kw">with</span>(lalonde, treat <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>treat)<span class="op">*</span>p.score2<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>p.score2))

<span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, <span class="dt">weights =</span> <span class="kw">c</span>(<span class="st">&quot;att.weights&quot;</span>, <span class="st">&quot;att.weights2&quot;</span>),
        <span class="dt">method =</span> <span class="st">&quot;weighting&quot;</span>, <span class="dt">estimand =</span> <span class="st">&quot;ATT&quot;</span>)</code></pre></div>
<p>When subclassification is used in conditioning, an argument to <code>subclass</code> must be specified; this can be a vector of subclass membership or the name of a variable in <code>data</code> containing subclass membership. <code>bal.tab()</code> produces a different type of output from when matching or weighting are used, though it has all of the same features. The default output is a balance table displaying balance aggregated across subclasses. Each cell contains the average statistic across the subclasses, but does not contain information on variance ratios. Using the arguments discussed above (except <code>disp.v.ratio</code> and <code>v.threshold</code>) will change the output as it does when only matching or weighting is used.</p>
<p>To examine balance within each subclass, the user can specify <code>disp.subclass = TRUE</code>, which will produce output for the subclasses in aggregate as well as for each subclass. Within subclasses, all the information above, including variance ratios, will be presented, except for statistics for the unadjusted groups (since the adjustment occurs by creating the subclasses), as specified by the user. See <code>?bal.tab.subclass</code> for more details.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Subclassification for ATT with 6 subclasses</span>
lalonde<span class="op">$</span>p.score &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, 
                       <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)<span class="op">$</span>fitted.values
nsub &lt;-<span class="st"> </span><span class="dv">5</span> <span class="co">#number of subclasses</span>
lalonde<span class="op">$</span>subclass &lt;-<span class="st"> </span><span class="kw">findInterval</span>(lalonde<span class="op">$</span>p.score, 
                                 <span class="kw">quantile</span>(lalonde<span class="op">$</span>p.score[lalonde<span class="op">$</span>treat <span class="op">==</span><span class="st"> </span><span class="dv">1</span>], 
                                          <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> nsub <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)), 
                                 <span class="dt">all.inside =</span> T)

<span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, <span class="dt">subclass =</span> <span class="st">&quot;subclass&quot;</span>, 
        <span class="dt">method =</span> <span class="st">&quot;subclassification&quot;</span>, <span class="dt">disp.subclass =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>When using <code>bal.tab()</code> with continuous treatments, the balance statistic presented is the (weighted) Pearson correlation between each covariate and treatment. Because of this, no parameters related to the computation of mean differences or variance ratios need to be specified. An additional parameter, <code>r.threshold</code>, functions like <code>m.threshold</code> and <code>v.threshold</code> and specifies the threshold for the absolute correlation between each covariate and treatment. Presently, there are no specific guidelines for the value <code>r.threshold</code> should take, but correlations close to 0 indicate (linear) independnece between each covariate and treatment, the same way mean differences close to 0 and variance ratios close to 1 indicate covariate-treatment independence. See the section “Using cobalt with continuous treatments” for more details.</p>
<p>The next two sections describe the use of <code>bal.tab()</code> with the <code>MatchIt</code> and <code>WeightIt</code>. As stated above, the arguments controlling calculations and display are largely the same across inputs types, so they will not be described again except when their use differs from that described in the present section.</p>
</div>
<div id="using-bal.tab-with-matchit" class="section level3">
<h3>Using <code>bal.tab()</code> with <code>MatchIt</code></h3>
<p>When using <code>bal.tab()</code> with <code>MatchIt</code>, fewer arguments need to be specified because information is stored in the <code>matchit</code> object, the output of a call to <code>matchit()</code>. <code>bal.tab()</code> is used very similarly to <code>summary()</code> in <code>MatchIt</code>: it takes in a <code>matchit</code> object as its input, and prints a balance table with the requested information. Below is a simple example of its use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;lalonde&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;cobalt&quot;</span>)
covs0 &lt;-<span class="st"> </span><span class="kw">subset</span>(lalonde, <span class="dt">select =</span> <span class="op">-</span><span class="kw">c</span>(treat, re78, nodegree, married))

<span class="co"># Nearest neighbor 2:1 matching with replacement</span>
<span class="kw">library</span>(<span class="st">&quot;MatchIt&quot;</span>) <span class="co">#if not yet loaded</span>
m.out &lt;-<span class="st"> </span><span class="kw">matchit</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, <span class="dt">method =</span> <span class="st">&quot;nearest&quot;</span>, 
                 <span class="dt">ratio =</span> <span class="dv">1</span>,  <span class="dt">replace =</span> <span class="ot">TRUE</span>)

<span class="kw">bal.tab</span>(m.out)</code></pre></div>
<p>The output looks very similar to <code>MatchIt</code>’s <code>summary()</code> function: at the top is the original <code>matchit()</code> call; next is the balance table, and finally is a summary of the sample size before and after adjustment.</p>
<p>Setting <code>binary = &quot;std&quot;</code> in <code>bal.tab()</code> will produce identical calculations to those in <code>MatchIt</code>’s <code>summary(m.out, standardize = TRUE)</code>, which produces standardized differences for binary variables as well as continuous variables. The other arguments to <code>bal.tab()</code> when using it with <code>MatchIt</code> have the same form and function as those given when using it without a conditioning package. The output when using <code>MatchIt</code> for subclassification is the same as that displayed previously.</p>
</div>
<div id="using-bal.tab-with-weightit" class="section level3">
<h3>Using <code>bal.tab()</code> with <code>WeightIt</code></h3>
<p>The <code>WeightIt</code> package is a convenient wrapper for the weighting functions of several packages, including <code>twang</code>, <code>CBPS</code>, <code>ebal</code>, <code>sbw</code>, and <code>ATE</code>, and allows for the estimation weights for binary, multinomial, and categorical treatments and both point and longitudinal treatments. It was designed to work seamlessly with <code>cobalt</code>, so using it with <code>cobalt</code> is very straightforward. Below is a simple example of using <code>bal.tab()</code> with <code>WeightIt</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;WeightIt&quot;</span>)
<span class="kw">data</span>(<span class="st">&quot;lalonde&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;cobalt&quot;</span>) <span class="co">#If not yet loaded</span>
covs0 &lt;-<span class="st"> </span><span class="kw">subset</span>(lalonde, <span class="dt">select =</span> <span class="op">-</span><span class="kw">c</span>(treat, re78, nodegree, married))

<span class="co">#Generating propensity score weights for the ATT</span>
W.out &lt;-<span class="st"> </span><span class="kw">weightit</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde,
                  <span class="dt">method =</span> <span class="st">&quot;ps&quot;</span>, <span class="dt">estimand =</span> <span class="st">&quot;ATT&quot;</span>)

<span class="kw">bal.tab</span>(W.out)</code></pre></div>
</div>
</div>
<div id="bal.plot" class="section level2">
<h2><code>bal.plot()</code></h2>
<p>The gold standard for covariate balance is multidimensional independence between treatment and covariates. Because this is hard to visualize and assess with the large numbers of covariates typical of causal effect analysis, univariate balance is typically assessed as a proxy. Most conditioning packages, as well as <code>cobalt</code>, will provide numerical summaries of balance, typically by comparing moments between the treated and control groups. But even univariate balance is more complicated than simple numerical summaries can address; examining distributional balance is a more thorough method to assess balance between groups. Although there are statistics such as the Kolmogorov-Smirnov distance that attempt to summarize distributional balance beyond the first few moments (Ali et al., 2016; Austin &amp; Stuart, 2015), complimenting statistics with a visual examination of the distributional densities can be an effective way of assessing distributional similarity between the groups (Ho et al., 2007).</p>
<p><code>bal.plot()</code> allows users to do so by displaying density plots, bar graphs, and scatterplots so that users can visually assess independence between treatment and covariates before and after conditioning. Below is an example of the use of <code>bal.plot()</code> after using propensity score weighting for the ATT using the output from <code>WeightIt</code> generated above.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bal.plot</span>(W.out, <span class="dt">var.name =</span> <span class="st">&quot;age&quot;</span>)
<span class="kw">bal.plot</span>(W.out, <span class="dt">var.name =</span> <span class="st">&quot;race&quot;</span>)</code></pre></div>
<p>The first argument (or set of arguments) is the sufficient set of arguments for a simple call to <code>bal.tab()</code>, defining the data object (e.g., the output of a conditioning function), the treatment indicators, and the weights or subclasses. See above for examples. The next argument is the name of the covariate for which distributional balance is to be assessed. If subclassification is used (i.e., if subclasses are present in the input data object or arguments), an additional argument <code>which.sub</code> can be specified, with a number corresponding to the subclass number for which balance is to be assessed on the specified covariate; if it is not specified, plots for all subclasses will be displayed.</p>
<p>The user can also specify whether distributional balance is to be shown before or after adjusting or both by using the argument to <code>which</code>. If <code>which = &quot;unadjusted&quot;</code>, balance will be displayed for the unadjusted sample only. If <code>which = &quot;both&quot;</code>, balance will be displayed for both the unadjusted sample and the adjusted sample. The default is to display balance for the adjusted sample.</p>
<p>The output of <code>bal.plot()</code> is a density plot for the two groups on the given covariate. For categorical or binary variables, a bar graph is displayed instead. The x-axis is the value of the variable, and the y-axis is the proportion density or proportion of the variable in the given group. When multi-category categorical variables are given, bars will be created for each level, unlike in <code>bal.tab()</code>, which splits the variable into several binary variables. The degree to which the density plots for the two groups overlap is a good measure of group balance on the given covariate; significant differences in shape can be indicative of poor balance, even when the mean differences and variance ratios are well within thresholds. Strong distributional similarity is especially important for variables strongly related to the outcome of interest.</p>
<p>Distributional balance can also be assessed on the distance measure, and this can form an alternative to other common support checks, like <code>MatchIt</code>’s <code>plot(..., type = &quot;hist&quot;)</code> or <code>twang</code>’s <code>plot(..., plots = &quot;boxplot&quot;)</code>. To examine the distributions of the distance measure, the input to <code>var.name</code> must be the name of the distance variable. If the data input object doesn’t already contain the distance measure (e.g., if not using one of the conditioning packages), the distance measure must be manually added as an input to <code>bal.plot()</code> through <code>distance</code>, in addition to being called through <code>var.name</code>. Below is an example using the formula input to <code>bal.plot()</code> to display the distributions of propensity scores before and after weighting adjustment:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Before and after weighting; which = &quot;both&quot;</span>
<span class="kw">bal.plot</span>(W.out, <span class="dt">var.name =</span> <span class="st">&quot;prop.score&quot;</span>, <span class="dt">which =</span> <span class="st">&quot;both&quot;</span>)</code></pre></div>
<p>It is generally not a useful assessment of balance to examine the overlap of the distance measure distributions after adjustment, as most conditioning methods will yield good distributional overlap on the distance measure whether or not balance is achieved on the covariates (Stuart et al., 2013). However, it may be useful to see the new range of the distance measure if calipers or common support pruning are used.</p>
<p>The output plot is made using <code>ggplot2</code>, which means that users familiar with <code>ggplot2</code> can adjust the plot with <code>ggplot2</code> commands.</p>
<p>When the treatment variable is continuous, users can use <code>bal.plot()</code> to examine and assess dependence between the covariate and treatment. The arguments given to <code>bal.plot()</code> are the same as in the binary treatment case, but the resulting plots are different. If the covariate is continuous, a scatterplot between the covariate and the treatment variable will be displayed, along with a linear fit line, a Loess curve, and a reference line indicating linear independence. Used together, these lines can help diagnose departurses from independence beyond the simple correlation coefficient. Proximity of the fit lines to the reference line is suggestive of independence between the covariate and treatment variable. If the covariate is categorical (including binary), density plots of the treatment variable for each category will be displayed. Densities that overlap completely are indicative of independence between the covariate and treatment. See the section “Using cobalt with continuous treatments” for more details and an example.</p>
</div>
<div id="love.plot" class="section level2">
<h2><code>love.plot()</code></h2>
<p>The Love plot is a summary plot of covariate balance before and after conditioning popularized by Dr. Thomas E. Love. In a visually appealing and clear way, balance can be presented to demonstrate to readers that balance has been met within a threshold, and that balance has improved after conditioning (which is not always the case; cf. King &amp; Nielsen, 2016). <code>love.plot()</code> does just this, providing the user with several options to customize their plot for presentation. Below is an example of its use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;lalonde&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;cobalt&quot;</span>)
covs &lt;-<span class="st"> </span><span class="kw">subset</span>(lalonde, <span class="dt">select =</span> <span class="op">-</span><span class="kw">c</span>(treat, re78))

<span class="co"># Nearest neighbor 1:1 matching with replacement</span>
<span class="kw">library</span>(<span class="st">&quot;MatchIt&quot;</span>) <span class="co">#if not yet loaded</span>
m.out &lt;-<span class="st"> </span><span class="kw">matchit</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs), <span class="dt">data =</span> lalonde, <span class="dt">method =</span> <span class="st">&quot;nearest&quot;</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)

<span class="kw">love.plot</span>(<span class="kw">bal.tab</span>(m.out), <span class="dt">threshold =</span> .<span class="dv">1</span>)</code></pre></div>
<p><code>love.plot()</code> takes as its first argument the output of a call to <code>bal.tab()</code>; this can be accomplished simply by inserting the call into the first argument or by saving the result of a call to <code>bal.tab()</code> to an object and inserting the object as the argument. There are several other arguments, all of which control display, and are described below.</p>
<p>The output is a plot with the balance statistic on the X-axis and the covariates output in <code>bal.tab()</code> on the Y-axis. Each point represents the balance statistic for that covariate, colored based on whether it is calculated before or after adjustment. The dotted lines represent the threshold set in the <code>threshold</code> argument; if most or all of the points after adjustment are within the threshold, that is good evidence that balance has been achieved.</p>
<p>The default is to present mean differences as they are calculated in the call to <code>bal.tab()</code>; by specifying <code>stat = &quot;variance.ratios&quot;</code> or <code>stat = &quot;ks.statistics&quot;</code> (abbreviations allowed), the user can request variance ratios or KS statistics instead. Because binary variables don’t have variance ratios calculated, there may be empty rows if variance ratios are requested, but these rows can be deleted by setting <code>no.missing = TRUE</code>.</p>
<p>The <code>threshold</code> argument works similarly to <code>m.threshold</code>, <code>v.threshold</code>, and <code>ks.threshold</code> in <code>bal.tab()</code>; specifying it is optional, but doing so will provide an additional point of reference on which to evaluate the displayed balance measures. If these thresholds are specified in <code>bal.tab()</code>, <code>love.plot()</code> will use them in the resultant plot with the corresponding balance statistic. The <code>threshold</code> argument to <code>love.plot()</code> takes precedence.</p>
<p>If mean difference are requested, <code>love.plot()</code> will use the mean differences as they are calculated by <code>bal.tab()</code> and presented in the mean differences columns of the balance table. See the section on using <code>bal.tab()</code> to see what the default calculations are for these values. If <code>abs = TRUE</code> in <code>love.plot()</code>, the plot will display absolute mean differences, which can aid in display clarity since the magnitude is generally the more important aspect of the statistic.</p>
<p>The order of the covariates displayed can be adjusted using the argument to <code>var.order</code>. If left empty or <code>NULL</code>, the covariates will be listed in alphabetical order. If <code>&quot;adjusted&quot;</code>, covariates will be ordered by the requested balance statistic of the adjusted sample. If <code>&quot;unadjusted&quot;</code>, covariates will be ordered by the requested balance statistic of the unadjusted sample, which tends to be more visually appealing. Abbreviations are allowed. The distance variable(s), if any, will always be displayed at the top. They can be omitted by setting <code>drop.distance = TRUE</code>.</p>
<p>The plot uses the original variable names as they are given in the data set, which may not be the names desired for display in publication. By using the argument to <code>var.names</code>, users can specify their own variable names to be used instead. To specify new variable names with <code>var.names</code>, the user must enter an object containing the new variable names and, optionally, the old variable names to replace. For options of how to do so, see the help file for <code>love.plot()</code> with <code>?love.plot</code>. Below is an example, creating a publication-ready plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">v &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">old =</span> <span class="kw">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;educ&quot;</span>, <span class="st">&quot;race_black&quot;</span>, <span class="st">&quot;race_hispan&quot;</span>, 
                        <span class="st">&quot;race_white&quot;</span>, <span class="st">&quot;married&quot;</span>, <span class="st">&quot;nodegree&quot;</span>, <span class="st">&quot;re74&quot;</span>, <span class="st">&quot;re75&quot;</span>, <span class="st">&quot;distance&quot;</span>),
                <span class="dt">new =</span> <span class="kw">c</span>(<span class="st">&quot;Age&quot;</span>, <span class="st">&quot;Years of Education&quot;</span>, <span class="st">&quot;Black&quot;</span>, 
                        <span class="st">&quot;Hispanic&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;Married&quot;</span>, <span class="st">&quot;No Degree Earned&quot;</span>, 
                        <span class="st">&quot;Earnings 1974&quot;</span>, <span class="st">&quot;Earnings 1975&quot;</span>, <span class="st">&quot;Propensity Score&quot;</span>))

<span class="kw">love.plot</span>(<span class="kw">bal.tab</span>(m.out), <span class="dt">stat =</span> <span class="st">&quot;mean.diffs&quot;</span>, <span class="dt">threshold =</span> .<span class="dv">1</span>, 
          <span class="dt">var.order =</span> <span class="st">&quot;unadjusted&quot;</span>, <span class="dt">var.names =</span> v, <span class="dt">abs =</span> <span class="ot">TRUE</span>,
          <span class="dt">line =</span> <span class="ot">TRUE</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</code></pre></div>
<p>This plot shows that balance was improved on almost all variables after adjustment, bringing all but one below the threshold of .1 for absolute mean differences.</p>
<p>When the treatment variable is continuous, <code>love.plot()</code> will display Pearson correlations between each covariate and treatment. The same arguments apply except that <code>stat</code> is ignored and <code>threshold</code> corresponds to <code>r.threshold</code>, the threshold for correlations.</p>
<p>Like the output of <code>bal.plot()</code>, the output of <code>love.plot()</code> is a <code>ggplot2</code> object, which means <code>ggplot2</code> users can modify the plot to some extent for presentation or publication. Several aspects of the appearance of the plot can be customized using the <code>love.plot()</code> syntax, including the size, shape, and color of the points, the title and subtitle of the plot, and whether to display lines connecting the points. See <code>?love.plot</code> for details. It may be challenging to make adjustments to these aspects using <code>ggplot2</code> syntax, so these arguments allow for some simple adjustments.</p>
</div>
</div>
<div id="additional-features" class="section level1">
<h1>Additional Features</h1>
<div id="using-cobalt-with-continuous-treatments" class="section level2">
<h2>Using <code>cobalt</code> with continuous treatments</h2>
<p>Although the most common use of propensity scores is in the context of binary treatments, it is also possible to use propensity scores with continuous treatment to estimate dose-response functions while controlling for background variables (Hirano &amp; Imbens, 2004). As in the binary case, the goal of propensity score adjustment in the continuous case is to arrive at a scenario in which, conditional on the propensity score, treatment is independent of background covariates. When this is true (and there are no unmeasured confounders), treatment is also indepnendent of potential outcomes, thereby meeting the strong ignorability requirememnt for causal inference.</p>
<p>Bia &amp; Mattei (2008) describe the use of the <code>gpscore</code> function in Stata, which appears to be highly effective for estimating and assessing dose-response functions for continuous treatments. In R, there are not many ways to estimate and condition on the propensity score in these contexts. It is possible, using the formulas described by Hirano &amp; Imbens (2004), to generate the propensity scores manually and perform weighting, subclassification, or covariate adjustment on them. In addition, the <code>CBPS</code> package is able to generate balancing weights for continuous treatments, using the method described by Fong &amp; Imai (2014). The <code>balance()</code> function in the <code>CBPS</code> package assesses balance after propensity score weighting using the covariate balancing propensity score.</p>
<p>In <code>cobalt</code>, users can assess and present balance for continuous treatments using <code>bal.tab()</code>, <code>bal.plot()</code>, and <code>love.plot()</code>, just as with binary treatments. The syntax is almost identical in both cases regardless of the type of treatment variable considered, but there are a few differences and specifics worth noting. The approach <code>cobalt</code> takes to assessing balance is to display correlations between each covariate and the treatment variable, which is the approach used in <code>CBPS</code>, but not that described in Hirano &amp; Imbens (2004) or implemented in <code>gpscore</code> (Bia &amp; Mattei, 2008), which involves stratifying on both the treatment variable and the propensity score and calculating mean differences.</p>
<p>Below is an example of the workflow for using propensity scores for continuous treatments in the <code>WeightIt</code> package. To demonstrate, we use the <code>lalonde</code> package included in <code>cobalt</code>, using an arbitrary continuous variable as the treatment, though substantively this analysis makes little sense.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;lalonde&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;cobalt&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;WeightIt&quot;</span>)
cov.c &lt;-<span class="st"> </span><span class="kw">subset</span>(lalonde, <span class="dt">select =</span> <span class="op">-</span><span class="kw">c</span>(treat, re78, re75))

<span class="co">#Generating weights with re75 as the continuous treatment</span>
W.out.c &lt;-<span class="st"> </span><span class="kw">weightit</span>(re75 <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>educ <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>married <span class="op">+</span><span class="st"> </span>nodegree <span class="op">+</span><span class="st"> </span>
<span class="st">                        </span>re74 <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(re74<span class="op">^</span><span class="dv">2</span>), 
                    <span class="dt">data =</span> lalonde, <span class="dt">method =</span> <span class="st">&quot;ps&quot;</span>)</code></pre></div>
<p>First, we can assess balance numerically using <code>bal.tab()</code>. The balance statistic used is the Pearson correlation between each covariate and the treatment variable. A threshold for balance on correlations can be specified using <code>r.threshold</code>; though there are no specific guidelines for this value, we choose .1 as indicating balance. Because the goal is complete independence between treatment and covariates, not simply the absence of a linear correlation between treatment and covariates, including interactions and squared terms through the use of <code>int = TRUE</code> is recommended. Here we use <code>imbalanced.only = TRUE</code>, which is available with all uses of <code>bal.tab()</code>, to restrict output to just those variables that have failed to meet the set balance threshold.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Assessing balance numerically</span>
<span class="kw">bal.tab</span>(W.out.c, <span class="dt">un =</span> <span class="ot">TRUE</span>, <span class="dt">r.threshold =</span> .<span class="dv">1</span>, <span class="dt">int =</span> <span class="ot">TRUE</span>,
        <span class="dt">imbalanced.only =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>We can also visually assess balance using <code>bal.plot()</code>. For continuous covariates, <code>bal.plot()</code> dispalys a scatterplot of treatment against the covariate, and includes a linear fit line (blue, dashed), a Loess curve (blue, solid), and a reference line (black, solid) at the (weighted) mean of the treatment variable. These three lines can be used to diagnose dependence. If either fit line is not close to flat (i.e., lying on top of the reference line), there may be some remaining dependence between treatment and the covariate. For categorical covariates, including binary, <code>bal.plot()</code> displays a density plot of the treatment variable in each category. If treatment and the covariate are independent, the densities for each category should overlap with each other. A distinct lack of overlap is indicative of remaining dependence between treatment and the covariate.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Assessing balance graphically</span>
<span class="kw">bal.plot</span>(W.out.c, <span class="st">&quot;re74&quot;</span>, <span class="dt">which =</span> <span class="st">&quot;both&quot;</span>)
<span class="kw">bal.plot</span>(W.out.c, <span class="st">&quot;married&quot;</span>, <span class="dt">which =</span> <span class="st">&quot;both&quot;</span>)</code></pre></div>
<p>When balance has been achieved to a satisfactory level, users can present balance improvements in a Love plot using the <code>love.plot()</code> command, just as with binary treatments.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Summarizing balance in a Love plot</span>
<span class="kw">love.plot</span>(<span class="kw">bal.tab</span>(W.out.c), <span class="dt">threshold =</span> .<span class="dv">1</span>, <span class="dt">abs =</span> <span class="ot">TRUE</span>, 
          <span class="dt">var.order =</span> <span class="st">&quot;unadjusted&quot;</span>, <span class="dt">line =</span> <span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="using-cobalt-with-multinomial-treatments" class="section level2">
<h2>Using <code>cobalt</code> with multinomial treatments</h2>
<p>When multiple categorical treatment are to be compared with each other, it is possible to create balance across the treatment groups using preprocessing methods. Lopez &amp; Gutman (2017) compare methods used to create balance with multinomial treatments and briefly describe balance assessment for these scenarios. An important note is the choice of estimand to be examined. The ATE represents the causal effect of moving from one tretament group to another for all units in the population; the ATT represents the causal effect of moving from one treatment group to another “focal” treatment group for just the units that wuld have been in the focal treatment group. The way balance is assessed in these scnaerios differs. For the ATE, all possible treatment pairs must be assessed for balance because all possible comparisons are potentially meaningful, but for the ATT, only treatment pairs that include the focal treatment group can be meaningfully compared, so balance needs only to be assessed in these pairs.</p>
<p>In <code>cobalt</code>, users can assess and present balance for multinomial treatments using <code>bal.tab()</code>, <code>bal.plot()</code>, and <code>love.plot()</code>, just as with binary treatments. The output is slightly different, though, and is similar to the output generated when using these functions with clusters. <code>bal.tab()</code> computes balance statistics for all pairwise comparsions between tretament groups and a table containing the worst balance for each covariate across pairwise comparisons. For mean differences, this is described in Lopez &amp; Gutman (2017) as “Max2SB,” or the maximum pairwise standardized bias. In <code>cobalt</code>, this has been extended to variance ratios and KS statistics as well. If the worst imbalance is not too great, then imbalance for all pairwsie comparisons will not be too great either. When the ATT is desired, a focal group must be specified (unless done so automatically for some methods), and only the treatment group comparisons that involve that focal group will be computed and displayed.</p>
<p><code>love.plot()</code> allows for the display of each pairwise treatment or the range of balance across treatment pairs for each covariate. <code>bal.plot()</code> displays distributional balance for the requetsed covariate across all treatment groups. Currently, multinomial treatments are not supported with clustered or multiply imputed data.</p>
<p>Below is an example of using <code>cobalt</code> with multinomial treatments. For this example, race will be the “treatment”; this type of analysis is not meant to be causal, but rather represents a method to examine disparities among groups accounting for covariates that might otherwise explain differences among groups. We will use <code>WeightIt</code> to generate balanced groups by estimating propensity score weights with multinomial logistic regression.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;lalonde&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;cobalt&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;WeightIt&quot;</span>)
cov.mn &lt;-<span class="st"> </span><span class="kw">subset</span>(lalonde, <span class="dt">select =</span> <span class="op">-</span><span class="kw">c</span>(treat, re78, race))

<span class="co">#Using WeightIt to generate weights</span>
W.out.mn &lt;-<span class="st"> </span><span class="kw">weightit</span>(<span class="kw">f.build</span>(<span class="st">&quot;race&quot;</span>, cov.mn), <span class="dt">data =</span> lalonde,
                     <span class="dt">method =</span> <span class="st">&quot;ps&quot;</span>)</code></pre></div>
<p>First, we can examine balance numerically using <code>bal.tab()</code>. There are three possible pairwise comparisons, all of which can be requested with <code>which.treat = NULL</code>. The summary across all pairwise comparisons is displayed as well, but it can be suppressed with <code>multi.summary = FALSE</code>. See <code>?bal.tab.multi</code> for more details.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Assessing balance numerically</span>
<span class="kw">bal.tab</span>(W.out.mn, <span class="dt">un =</span> <span class="ot">TRUE</span>, <span class="dt">which.treat =</span> <span class="ot">NULL</span>)

<span class="co">#Just black vs. white</span>
<span class="kw">bal.tab</span>(W.out.mn, <span class="dt">un =</span> <span class="ot">TRUE</span>, <span class="dt">disp.means =</span> <span class="ot">TRUE</span>,
        <span class="dt">which.treat =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;white&quot;</span>),
        <span class="dt">multi.summary =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>We can also assess balance graphically. The same guidelines apply for multinomial treatments as do for binary treatments. Ideally, covariate distributions will look similar across all treatment groups. If only a subset of treatment groups are to be compared, these can be specified with an argument to <code>which.treat</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Assessing balance graphically</span>
<span class="kw">bal.plot</span>(W.out.mn, <span class="st">&quot;age&quot;</span>, <span class="dt">which =</span> <span class="st">&quot;both&quot;</span>)

<span class="kw">bal.plot</span>(W.out.mn, <span class="st">&quot;married&quot;</span>, <span class="dt">which =</span> <span class="st">&quot;both&quot;</span>,
         <span class="dt">which.treat =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;white&quot;</span>))</code></pre></div>
<p>Finally, we can use <code>love.plot()</code> to display balance across treatments. By default, <code>love.plot()</code> displays the values in the summary across pairwsie comparisons. To request individual treatment comparisons, use <code>which.treat = NULL</code> in either <code>bal.tab()</code> or <code>love.plot()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Summarizing balance in a Love plot</span>
<span class="kw">love.plot</span>(<span class="kw">bal.tab</span>(W.out.mn), <span class="dt">threshold =</span> .<span class="dv">1</span>,
          <span class="dt">which.treat =</span> <span class="ot">NULL</span>)</code></pre></div>
</div>
<div id="comparing-balancing-methods" class="section level2">
<h2>Comparing balancing methods</h2>
<p>It is possible to display balance for multiple balancing methods at the same time in <code>bal.tab()</code>, <code>bal.plot()</code>, and <code>love.plot()</code>. Do do so, weights generated from each balancing mehtod need to be supplid together in each call. For example, we can compare matching and inverse probability weighting for the ATT using the following code and the output generated above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, 
        <span class="dt">weights =</span> <span class="kw">data.frame</span>(<span class="dt">Matched =</span> <span class="kw">get.w</span>(m.out),
                             <span class="dt">IPW =</span> <span class="kw">get.w</span>(W.out)),
        <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;matching&quot;</span>, <span class="st">&quot;weighting&quot;</span>), 
        <span class="dt">disp.v.ratio =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>To use <code>bal.plot()</code>, the same syntax can be used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bal.plot</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, 
         <span class="dt">weights =</span> <span class="kw">data.frame</span>(<span class="dt">Matched =</span> <span class="kw">get.w</span>(m.out),
                              <span class="dt">IPW =</span> <span class="kw">get.w</span>(W.out)),
         <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;matching&quot;</span>, <span class="st">&quot;weighting&quot;</span>), 
         <span class="dt">var.name =</span> <span class="st">&quot;age&quot;</span>, <span class="dt">which =</span> <span class="st">&quot;both&quot;</span>)</code></pre></div>
<p>With <code>love.plot()</code>, <code>var.order</code> can be <code>&quot;unadjusted&quot;</code>, <code>&quot;alphabetical&quot;</code>, or one of the names of the weights to order the variables. Also, <code>colors</code> and <code>shapes</code> should have the same length as the number of weights or have length 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">love.plot</span>(<span class="kw">bal.tab</span>(<span class="kw">f.build</span>(<span class="st">&quot;treat&quot;</span>, covs0), <span class="dt">data =</span> lalonde, 
                  <span class="dt">weights =</span> <span class="kw">data.frame</span>(<span class="dt">Matched =</span> <span class="kw">get.w</span>(m.out),
                                       <span class="dt">IPW =</span> <span class="kw">get.w</span>(W.out)),
                  <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;matching&quot;</span>, <span class="st">&quot;weighting&quot;</span>)), <span class="dt">var.order =</span> <span class="st">&quot;unadjusted&quot;</span>,
          <span class="dt">abs =</span> <span class="ot">TRUE</span>, <span class="dt">colors =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>), 
          <span class="dt">shapes =</span> <span class="kw">c</span>(<span class="dv">21</span>, <span class="dv">22</span>, <span class="dv">23</span>))</code></pre></div>
</div>
<div id="using-the-prognostic-score-for-balance-assessment" class="section level2">
<h2>Using the prognostic score for balance assessment</h2>
<p>The prognostic score is the model-predicted outcome for an individual, excluding the treatment variable in the model (Hansen, 2008). Stuart et al. (2013) found that prognostic scores can be an extremely effective tool for assessing balance, greatly outperforming mean differences on covariates and significance tests. This is true even if the prognostic score model is slightly misspecified. Although the use of prognostic scores appears to violate the spirit of preprocessing in that users observe the outcome variable prior to treatment effect estimation, typically the prognostic score model is estimated in just the control group, so that the outcome of the treated group (which may contain treatment effect information) is excluded from analysis.</p>
<p>Assessing balance on the prognostic score is simple in <code>cobalt</code>, and highly recommended when available. The steps are:</p>
<ol style="list-style-type: decimal">
<li>Estimate the outcome model in the control group</li>
<li>Generate model-predicted outcome values for both the treated and control groups</li>
<li>Assess balance on prognostic scores by comparing standardized mean differences</li>
</ol>
<p>To use prognostic scores in <code>cobalt</code>, simply add the prognostic score as a variable in the argument to <code>distance</code>. Below is an example of how to do so after a call to <code>matchit()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ctrl.data &lt;-<span class="st"> </span>lalonde[lalonde<span class="op">$</span>treat <span class="op">==</span><span class="st"> </span><span class="dv">0</span>,]
ctrl.fit &lt;-<span class="st"> </span><span class="kw">glm</span>(re78 <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>educ <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>
<span class="st">                    </span>married <span class="op">+</span><span class="st"> </span>nodegree <span class="op">+</span><span class="st"> </span>re74 <span class="op">+</span><span class="st"> </span>re75,
                <span class="dt">data =</span> ctrl.data)
lalonde<span class="op">$</span>prog.score &lt;-<span class="st"> </span><span class="kw">predict</span>(ctrl.fit, lalonde)

<span class="kw">bal.tab</span>(m.out, <span class="dt">distance =</span> lalonde[<span class="st">&quot;prog.score&quot;</span>])</code></pre></div>
<p>Although the prognostic score is sensitive to the outcome estimation model used, a defensible prognostic score model can yield valid prognostic scores, which can then be used in balance assessment. In the above example, balance on the estimated prognostic score was good, so we can have some confidence that the effect estimate will be relatively unbiased, even though the “age” variable remains imbalanced. The logic is that that age is not a highly prognostic variable, which could be demonstrated by examining the standardized regression output of prognostic score model, so even though imbalance remains, such imbalance is unlikely to affect the effect estimate. The variables “re74” and “re75”, though, which are highly prognostic of the outcome, are quite balanced, thereby supporting an unbiased treatment effect estimate.</p>
</div>
</div>
<div id="details-on-calculations" class="section level1">
<h1>Details on Calculations</h1>
<p>There are calculations in <code>cobalt</code> that may be opaque to users; this section explains them.</p>
<div id="variance-in-standardized-mean-differences" class="section level2">
<h2>Variance in Standardized Mean Differences</h2>
<p>When computing a standardized mean difference, the raw mean difference is divided by a standard deviation, yielding a d-type effect size statistic. In <code>bal.tab()</code>, the user can control whether the standard deviation is that of the treated group or control group or a pooled estimate, calculated as the square root of the average of the group variances. In most applications, the standard deviation corresponding to the default for the method is the most appropriate.</p>
<p>A key detail is that the standard deviation, no matter how it is calculated, is always calculated using the unadjusted sample<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. This is line with how <code>MatchIt</code> computes standardized mean differences, and is recommended by Stuart (2008; 2010). One reason to favor the use of the standard deviation of the unadjusted sample is that it prevents the paradoxical situation that occurs when adjustment decreases both the mean difference and the spread of the sample, yielding a larger standardized mean difference than that prior to adjustment, even though the adjusted groups are now more similar. By using the same standard deviation before and after adjusting, the change in balance is isolated to the change in mean difference, rather than being conflated with an accompanying change in spread. It is important to note that both <code>twang</code> and <code>Matching</code> calculate standardized mean differences using the standard deviation of the sample in question, not the unadjusted sample, though <code>CBPS</code> uses the standard deviation of the unadjusted sample.</p>
</div>
<div id="weighted-variance" class="section level2">
<h2>Weighted Variance</h2>
<p>When using weighting or matching, summary values after adjustment are calculated by using weights generated from the matching or weighting process. For example, group means are computed using the standard formula for a weighted mean, incorporating the weighting or matching weights into the calculation. To estimate a weighted sample variance for use in variance ratios<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>, there are two formulas that have been proposed:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\frac{\sum_{i=1}^{n} w_{i}(x_{i} - \bar{x}_{w})^2}{(\sum_{i=1}^{n} w_{i}) - 1}\)</span></p></li>
<li><p><span class="math inline">\(\frac{\sum_{i=1}^{n} w_{i}}{(\sum_{i=1}^{n} w_{i})^2 - \sum_{i=1}^{n} w^2_{i}} \sum_{i=1}^{n} w_{i}(x_{i} - \bar{x}_{w})^2\)</span></p></li>
</ol>
<p>The weights used in the first formula are often called “frequency weights”, while the weights in the second formula are often called normalized or “reliability weights”. <code>MatchIt</code>, <code>twang</code>, and <code>Matching</code> all use the first formula when calculating any weighted variance (<code>CBPS</code> does not compute a weighted variance). However, Austin (2008) and Austin &amp; Stuart (2015) recommend the second formula when considering matching weights for k:1 matching or weights for propensity score weighting. In <code>cobalt</code>, as of version 2.0.0, the second formula is used to remain in line with recommended practice. For some applications (e.g., when all weights are either 0 or 1, as in 1:1 matching), the two formulas yield the same variance estimate. In other cases, the estimates are nearly the same.</p>
</div>
<div id="effective-sample-size-for-weighting" class="section level2">
<h2>Effective Sample Size for Weighting</h2>
<p>Knowledge of the sample size after adjustment is important not just for outcome analysis but also for assessing the adequacy of a conditioning specification. For example, pruning many units through common support cutoffs, caliper matching, or matching with replacement can yield very small sample sizes that hurt both the precision of the outcome estimate and the external validity of the conclusion. In matching, the sample size is fairly straightforward; it is simply the number of units remaining after matching<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>. In weighting, the sample size is not so straightforward because the purpose of weighting is to down- and up-weight observations to create two similar samples. The “effective sample size” (ESS) is a measure of the sample size a non-weighted sample would have to have to achieve the same level of precision as the weighted sample (Ridgeway et al., 2016). This measure is implemented in <code>twang</code> using the following formula: <span class="math display">\[ESS = \frac{(\sum_{i=1}^{n} w_{i})^2}{\sum_{i=1}^{n} w_{i}^2}\]</span> The authors claim that the ESS as calculated above is accurate when the estimand is the ATT, but will underestimate the true effective sample size when the estimate is the ATE.</p>
</div>
</div>
<div id="whats-missing-in-cobalt" class="section level1">
<h1>What’s Missing in <code>cobalt</code></h1>
<p>Compared to the other packages, <code>cobalt</code> may appear quite sparse. A fair amount is missing in <code>cobalt</code> that is present in other packages. Though there is value in many of the aspects that <code>cobalt</code> lacks, many were purposefully excluded based on methodological recommendations that conflict with the current use of some other packages. Below are aspects that are intentionally missing from <code>cobalt</code> that users may be used to from other packages. Their reasons for exclusion are included, with the hope that users of <code>cobalt</code> will be satisfied with what is available and be confident they are using the most methodologically sound tools for balance assessment.</p>
<div id="test-statistics-and-p-values" class="section level2">
<h2>Test Statistics and P-values</h2>
<p>Some of the early literature on propensity score matching included measures for balance assessment that relied on hypothesis tests for the independence of treatment assignment and covariates after adjustment (e.g., Rosenbaum &amp; Rubin, 1983; Hansen, 2004). In a review of propensity score applications in the social sciences, Thoemmes &amp; Kim (2011) found that over 66% of studies used significance tests to assess balance. Likewise, Austin (2008) found that over 70% of studies using propensity scores in the medical literature used significance tests to assess balance, a finding replicated by Ali et al. (2015). These hypothesis tests can come in many forms: t-tests for the difference in means between groups, chi-square tests for the difference in proportion between groups, Kolmogorov-Smirnov tests for the difference in cumulative density between groups, or F-tests for the difference in means between groups across subclasses.</p>
<p>The use of hypothesis tests appears natural here: if balance is achieved, we would not expect extreme values for the test statistics, and we can quantify the probability of observing imbalance as extreme as the one observed if no imbalance is present as a way to assess whether there is balance, as we can do with standard hypothesis testing. But this view is not shared by the methodological community: virtually all contemporary propensity score methodologists recommend against using hypothesis tests for balance assessment (e.g., Austin, 2009; 2011; Ho et al., 2007; Imai et al., 2008; Stuart, 2010; Thoemmes &amp; Kim, 2011; Ali et al., 2015). There are logical reasons for this preference against hypothesis tests, noted clearly in Ali et al. (2015) and Linden (2015): they are influenced by sample size, which fluctuates during adjustment, and the theory behind them is inappropriate because balance is a quality solely of the sample in question, not in relation to a population. The relevant information in a hypothesis test for group differences is the standardized magnitude of the group difference, and so such a measure is preferred.</p>
<p>Because hypothesis tests can be misleading and their use is discouraged by leading methodologists, they have been completely excluded in <code>cobalt</code> in favor of summary statistics. This stands in contrast to <code>twang</code>, <code>Matching</code>, and <code>RItools</code>, all of which report hypothesis test p-values in their balance output.</p>
</div>
<div id="q-q-plots-and-summaries" class="section level2">
<h2>Q-Q Plots and Summaries</h2>
<p>Q-Q plots have been recommended as tools to assess distributional balance of covariates between groups (Ho et al., 2007), and are implemented in <code>MatchIt</code> and <code>Matching</code> (<code>twang</code> implements them but for a different purpose). Statistics summarizing the degree of imbalance in Q-Q plots are also reported in both <code>MatchIt</code> and <code>Matching</code>. <code>MatchIt</code>’s <code>summary()</code> command by default reports “eQQ Med”, “eQQ Mean”, and “eQQ Max” for each covariate before and after adjustment. These are the median, mean, and maximum distance between the treated and control group empirical Q-Q plots on the scale of the covariate. When <code>standardize = TRUE</code>, the values reported are “eCDF Med”, “eCDF Mean”, and “eCDF Max”, which are the same values as above but computed using the empircal cumulative densities. The <code>Matching</code> package also provides all of these values. Values close to 0 indicate good balance between groups for the given covariate.</p>
<p>A weakness of empirical Q-Q plots is that they don’t reveal much about the differences in the shapes of the distributions between the groups, which is a key aspect of distributional balance. A density plot essentially contains the same information, but is clearer and more intuitive. Although the assessment of balance using an empirical Q-Q plot is straightforward (i.e., deviations from the 45-degree line indicate imbalances), density plots present the information in a way more in line with the actual goals of conditioning, in particular, that the distributions of treated and control units are similar (Ho et al., 2007). Empirical Q-Q plot summary statistics may be useful in quantifying imbalance, but currently there are no recommendations for their use, and no precedents in the applied literature either.</p>
</div>
</div>
<div id="whats-added-in-cobalt" class="section level1">
<h1>What’s Added in <code>cobalt</code></h1>
<p>There are several features in <code>cobalt</code> that are present in few, if any, balance assessment tools in the major packages. These come from methodological recommendations and requests by members of the methodological community.</p>
<div id="density-plots" class="section level2">
<h2>Density Plots</h2>
<p>As mentioned above, <code>cobalt</code> displays density plots and bar charts rather than empirical Q-Q plots for the assessment of distributional similarity. These charts are not standard in any of the conditioning packages, but can be an intuitive and helpful tool for deciding whether adjustment has yielded similar distributions between the groups for given covariates. Though there are no obvious heuristics for deciding how much dissimilarity is too much dissimilarity, density plots do avoid the sometimes confusing logic of empirical Q-Q plots in favor of simplicity and interpretability. Austin (2009) and Linden (2015) consider density plots as a compliment to empirical Q-Q plots to more finely examine balance after adjusting.</p>
</div>
<div id="variance-ratios" class="section level2">
<h2>Variance Ratios</h2>
<p>Although mean differences (including t-tests and chi-square tests) are the most reported balance statistic (Thoemmes &amp; Kim, 2011), variance ratios have been recommended in the literature as a means to further examine balance between groups (Austin, 2009, Imai et al., 2008; Ho et al., 2007). When group variances are similar, the variance ratio will be close to 1. Common thresholds for the variance ratio for balanced groups are 1/2 and 2 (Rubin, 2001; Stuart, 2010), though ratios closer to 1 are preferred. The <code>Matching</code> package is the only one of the conditioning packages that presents variance ratios for covariates. Although <code>bal.tab()</code> in <code>cobalt</code> does not display variance ratios by default, they can be easily requested and have thresholds set.</p>
</div>
<div id="distinguishing-continuous-and-binary-covariates" class="section level2">
<h2>Distinguishing Continuous and Binary Covariates</h2>
<p>Continuous and binary covariates are treated differently by default in <code>bal.tab()</code> and <code>bal.plot()</code>. For continuous covariates, the standard manipulations apply: standardized mean differences, variance ratios, and density plots. For binary covariates, raw differences in proportion and bar charts are preferable, and variance ratios are useless.</p>
<p>The value of standardized mean differences for continuous variables is that they are on the same scale so that they can be compared across variables, and they allow for a simple interpretation even when the details of the variable’s original scale are unclear to the analyst. None of these advantages are passed to binary variables because binary variables are already on the same scale (i.e., a proportion), and the scale is easily interpretable. In addition, the details of standardizing the proportion difference of a binary variable involve dividing the proportion difference by a variance, but the variance of a binary variable is a function of its proportion (Austin, 2009). Standardizing the proportion difference of a binary variable can yield the following counterintuitive result: if <span class="math inline">\(X_{T} = .2\)</span> and <span class="math inline">\(X_{C} = .3\)</span>, the standardized difference in proportion would be different from that if <span class="math inline">\(X_{T} = .5\)</span> and <span class="math inline">\(X_{C} = .6\)</span>, even though the expectation is that the balance statistic should be the same for both scenarios because both would yield the same degree of bias in the effect estimate. In addition, Ali et al. (2014) found that the raw difference in proportion was a better predictor of bias than the standardized mean difference for binary variables<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>.</p>
<p><code>MatchIt</code> allows users to view either standardized mean differences for all covariates or raw differences for all covariates, and <code>twang</code> and <code>Matching</code> display standardized differences for all variables but calculate test statistics depending on whether the covariate is continuous or binary (<code>CBPS</code> does not calculate mean differences, but presents both standardized and unstandardized means for all covariates). <code>cobalt</code> allows the user to select how the differences are to be calculated separately for continuous and binary variables, and uses the intuitive default that mean differences for continuous variables should be standardized while proportion differences for binary variables should not be.</p>
<p>Because the variance of a binary variable is a function only of its proportion, the variance ratio of a binary variable in two groups is a function only of their proportions, thereby containing no more information than the simple difference in proportion. Therefore, for binary variables, <code>cobalt</code> does not compute variance ratios, as they can be misleading. <code>Matching</code>, the only package that computes variance ratios for balance assessment, does so both for continuous and binary variables.</p>
</div>
<div id="interactions" class="section level2">
<h2>Interactions</h2>
<p>Because the goal of a balancing procedure is to achieve independence between treatment and the joint distribution of covariates, evaluating univariate distributional similarity may not be sufficient for assessing balance completely. Some writers have recommended the evaluation of distributional similiarity of interaction terms to account for this. Rather than requiring the user to create interaction variables by hand, <code>bal.tab()</code> can produce balance statistics for interactions by specifying <code>int = TRUE</code>, which also produces polynomial terms, similar to <code>MatchIt</code>’s <code>summary()</code>.</p>
<p>When including categorical variables in balance assessment, <code>bal.tab()</code> makes a few adjustments under the hood that deserve explanation. First, if a variable is binary and is entered as a factor variable, balance statistics will only be displayed for one level of the variable (since the other is redundant), but balance on interaction terms will be dislayed for all values of the variables. This distinguishes <code>bal.tab()</code> from <code>MatchIt</code>’s <code>summary()</code>, which always excludes one level of a factor variable when presented in both main effects and interactions. This might be desirable (especially when there are only two levels) in order to declutter output and reduce redunancy, but valuable balance information is made inaccessible.</p>
<p>For example, consider a binary variable “Sex” with values “Male” and “Female”. Many functions, including <code>bal.tab()</code>, <code>lm()</code>, and <code>matchit()</code>, will split this variable into two numeric dummy variables, “Male” and “Female”, each of which take on the values 0 and 1. One of these new variables is completley redundant: all of the relevant informaton is stored in just “Female”, so “Male” can be eliminated. Consider now a variable “Age”: what is desired in balance assessment is the interaction between Age and Sex; distributional similarity on the interaction between the treated and untreated groups is evidence of multivariate balance. Computing the interaction between “Female” and “Age” yields a variable that is “Age” when the unit is female and 0 otherwise. The average value of this variable is the average age of females in the sample, weighted by the proportion of females. If the two treatment groups have similar average values of this variable, this is taken as evidence for balance on the interaction between sex and age, though it is entirely possible that the average age of men differs greatly between the two groups. Thus, an additional variable computed as the product of “Male” and “Age” would be necessary to fully assess balance on the interaction between sex and age. <code>bal.tab()</code> produces this interaction term, which would otherwise be unobserved by the analyst<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>. The interactions among levels of a single factor, which always be equal to 0, are exlcuded in <code>bal.tab()</code>, but not in <code>MatchIt</code>’s <code>summary()</code>.</p>
<p>Interactions between the distance measure and other variables have been excluded in <code>bal.tab()</code>, noting that balance on the distance measure is neither necessary nor sufficient for covariate balance.</p>
<p>Because the number of computations increases both with sample size and number of variables, computing interactions can be slow. In addition to taking the product of varables two at a time, <code>bal.tab()</code> checks variables to ensure no variables were created that contain only a single value (e.g., interactions between mutually exclusive covariates) or are redundant with respect to other variables (e.g., manually created interactions or manually split factors). This results in cleaner, more useful output, but also requires more computing time. It is advisable to store the results of a call to <code>bal.tab()</code> to a variable to be accessed later rather than to call <code>bal.tab()</code> several times when using it with interactions.</p>
</div>
<div id="love-plots" class="section level2">
<h2>Love Plots</h2>
<p>Love plots and other similar plots that graphically display covariate balance before and after matching appear with some frequency in the applied and methodological literature (e.g., Ahmed et al., 2007; Austin, 2009; Austin &amp; Stuart, 2015). Several of the conditioning packages implement a similar plot: <code>MatchIt</code>’s <code>plot(summary(..., standardize = TRUE))</code> and <code>twang</code>’s <code>plot(..., plots = &quot;es&quot;)</code> present line plots showing the change in balance for each covariate. Below are examples of <code>twang</code>’s balance plot (above) and <code>cobalt</code>’s Love plot (below).</p>
<p>A Love plot displays the same information, but allows for the clear display of both the balance statistic value and the variable name, unlike the line plot above which displays only the balance statistic value. The Love plot in <code>cobalt</code> allows for a great deal of flexibility in appearance, and can present variance ratios as well as mean differences.</p>
</div>
<div id="clusters" class="section level2">
<h2>Clusters</h2>
<p>The use of preprocessing techniques in the context of multilevel data (e.g., students within schools, patients within hospitals) has been increasing. Currently no other package allows for any balance assessment with respect to clusters, except by manually examining balance on clusters specified manually. It can be useful to examine balance within each cluster, but, especially if there are many clusters, it may also be useful to examine a summary of balance across clusters. In all of its functions, <code>cobalt</code> provides options for displaying balance on clustered data sets. This can occur either within specified clusters or across all clusters. Details on using <code>cobalt</code> with clustered data can be found in the accompanying Appendix 2.</p>
</div>
<div id="multiply-imputed-data" class="section level2">
<h2>Multiply Imputed Data</h2>
<p>Missing data is frequent in all research involving human subjects, and especially in the large survey data sets that are often used to answer causal questions in the social sciences. Multiple imputation is a popular solution to this problem, and <code>cobalt</code> has features designed especially for assessing balance on preprocessed data sets that have been multiply imputed to address covariate missingness. Although the guidelines on assessing balance on multiply imputed data sets are thin, it is valuable to assess balance within and across imputed data sets to ensure the preprocessing solution is applicable to all imputaitons. Details on using <code>cobalt</code> with multiply imputed data can be found in the accompanying Appendix 2.</p>
</div>
</div>
<div id="for-programmers-integrating-cobalt-with-your-package" class="section level1">
<h1>For Programmers: Integrating <code>cobalt</code> with Your Package</h1>
<p>If you are designing a new R package for preprocessing that performs similar functions to <code>MatchIt</code>, <code>twang</code>, <code>Matching</code>, <code>optmatch</code>, <code>CBPS</code>, or <code>ebal</code>, you might consider integrating <code>cobalt</code> into your package to avoid programming your own balance assessment tool. The simplest way to do so is to have the output of your preprocessing function contain all the elements for use with the formula or data frame interfaces for <code>bal.tab()</code> and <code>bal.plot()</code>. You are also welcome to contact me to discuss the addition of a <code>bal.tab()</code> method for the output of your preprocessing function, which might ease the burden on users by allowing for fewer inputs and decisions (as is done with <code>MatchIt</code>’s output objects, for example).</p>
<p>As <code>cobalt</code> is updated to remain in line with methodological recommendations, the balance assessment capabilities for your function’s output will also improve if <code>cobalt</code> is a balance assessment tool for your package. In this way, users of your package can use the most up-to-date balance assessment tools programmed in <code>cobalt</code> without you having to update your package.</p>
<p>If you develop a new balance assessment tool, this may also be able to be integrated into <code>cobalt</code>, especially if it would be applicable to balance assessment generally in matching, weighting, or subclassification. Incorporating a new tool into <code>cobalt</code> may be a good way to broaden its use.</p>
</div>
<div id="acknowledgments" class="section level1">
<h1>Acknowledgments</h1>
<p>I thank Kirsten Kainz and Elizabeth Stuart for their support and advice on <code>cobalt</code>’s creation. I thank Zachary Fisher and Brian Barkley for their advice on developing an R package.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Ahmed, A., Rich, M.W., Sanders, P.W., Perry, G.J., Bakris, G.L., Zile, M.R., Love, T.E., Aban, I.B. &amp; Shlipak, M.G. (2007) Chronic kidney disease associated mortality in diastolic versus systolic heart failure: a propensity matched study. The American journal of cardiology, 99(3), pp.393-398.</p>
<p>Ali, M. S., Groenwold, R. H. H., Belitser, S. V., Pestman, W. R., Hoes, A. W., Roes, K. C. B., … Klungel, O. H. (2015). Reporting of covariate selection and balance assessment in propensity score analysis is suboptimal: a systematic review. Journal of Clinical Epidemiology, 68(2), 122–131. <a href="http://doi.org/10.1016/j.jclinepi.2014.08.011" class="uri">http://doi.org/10.1016/j.jclinepi.2014.08.011</a></p>
<p>Ali, M. S., Groenwold, R. H. H., Pestman, W. R., Belitser, S. V., Roes, K. C. B., Hoes, A. W., … Klungel, O. H. (2014). Propensity score balance measures in pharmacoepidemiology: a simulation study. Pharmacoepidemiology and Drug Safety, 23(8), 802–811. <a href="https://doi.org/10.1002/pds.3574" class="uri">https://doi.org/10.1002/pds.3574</a></p>
<p>Austin, P. C. (2008). A critical appraisal of propensity-score matching in the medical literature between 1996 and 2003. Statistics in Medicine, 27(12), 2037–2049. <a href="http://doi.org/10.1002/sim.3150" class="uri">http://doi.org/10.1002/sim.3150</a></p>
<p>Austin, P. C. (2009). Balance diagnostics for comparing the distribution of baseline covariates between treatment groups in propensity-score matched samples. Statistics in Medicine, 28(25), 3083–3107. <a href="http://doi.org/10.1002/sim.3697" class="uri">http://doi.org/10.1002/sim.3697</a></p>
<p>Austin, P. C. (2011). An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies. Multivariate Behavioral Research, 46(3), 399–424. <a href="http://doi.org/10.1080/00273171.2011.568786" class="uri">http://doi.org/10.1080/00273171.2011.568786</a></p>
<p>Austin, P. C., &amp; Stuart, E. A. (2015). Moving towards best practice when using inverse probability of treatment weighting (IPTW) using the propensity score to estimate causal treatment effects in observational studies. Statistics in Medicine, 34(28), 3661–3679. <a href="http://doi.org/10.1002/sim.6607" class="uri">http://doi.org/10.1002/sim.6607</a></p>
<p>Belitser, S. V., Martens, E. P., Pestman, W. R., Groenwold, R. H. H., de Boer, A., &amp; Klungel, O. H. (2011). Measuring balance and model selection in propensity score methods. Pharmacoepidemiology and Drug Safety, 20(11), 1115–1129. <a href="http://doi.org/10.1002/pds.2188" class="uri">http://doi.org/10.1002/pds.2188</a></p>
<p>Fong, C., Ratkovic, M., Hazlett, C., Yang, X., &amp; Imai, K. (2016). CBPS: Covariate Balancing Propensity Score. R package version 0.11. <a href="https://CRAN.R-project.org/package=CBPS" class="uri">https://CRAN.R-project.org/package=CBPS</a></p>
<p>Greifer, N. (2017). WeightIt: Weighting for Covariate Balance in Observational Studies. R package version 0.1.0.</p>
<p>Hainmueller, J. (2014). ebal: Entropy reweighting to create balanced samples. R package version 0.1-6. <a href="https://CRAN.R-project.org/package=ebal" class="uri">https://CRAN.R-project.org/package=ebal</a></p>
<p>Hansen, B. B. (2004). Full matching in an observational study of coaching for the SAT. Journal of the American Statistical Association, 99(467), 609-618.</p>
<p>Hansen, B. B. (2008). The prognostic analogue of the propensity score. Biometrika, 95(2), 481-488.</p>
<p>Hansen, B.B. and Klopfer, S.O. (2006) Optimal full matching and related designs via network flows. Journal of Computational and Graphical Statistics, 15, 609-627.</p>
<p>Hirano, K., and G. W. Imbens. (2004) The Propensity Score with Continuous Treatments. in Applied Bayesian Modeling and Causal Inference From Incomplete Data Perspectives, edited by A.Gelman and X. L.Meng. England : West Sussex, 2004: 73–84.</p>
<p>Ho, D. E., Imai, K., King, G., &amp; Stuart, E. A. (2007). Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference. Political Analysis, 15(3), 199–236. <a href="http://doi.org/10.1093/pan/mpl013" class="uri">http://doi.org/10.1093/pan/mpl013</a></p>
<p>Ho, D. E., Imai, K., King, G., &amp; Stuart, E. A. (2011). MatchIt: Nonparametric preprocessing for parametric causal inference. Journal of Statistical Software, 42, 1–28. Retrieved from <a href="http://www.jstatsoft.org/v42/i08/" class="uri">http://www.jstatsoft.org/v42/i08/</a></p>
<p>Imai, K., King, G., &amp; Stuart, E. A. (2008). Misunderstandings between experimentalists and observationalists about causal inference. Journal of the royal statistical society: series A (statistics in society), 171(2), 481-502.</p>
<p>Keller, B., &amp; Tipton, E. (2016). Propensity Score Analysis in R: A Software Review. Journal of Educational and Behavioral Statistics, 41(3), 326-348.</p>
<p>King, G., &amp; Nielsen, R. (2016). Why propensity scores should not be used for matching.</p>
<p>Linden, A. (2015), Graphical displays for assessing covariate balance in matching studies. Journal of Evaluation in Clinical Practice, 21: 242–247. <a href="http://doi.org/10.1111/jep.12297" class="uri">http://doi.org/10.1111/jep.12297</a></p>
<p>Lopez, M. J., &amp; Gutman, R. (2017). Estimation of causal effects with multiple treatments: a review and new ideas. arXiv:1701.05132 [Stat]. Retrieved from <a href="http://arxiv.org/abs/1701.05132" class="uri">http://arxiv.org/abs/1701.05132</a></p>
<p>Ridgeway, G., McCaffrey, D., Morral, A., Burgette, L., &amp; Griffin, B. A. (2016). Toolkit for Weighting and Analysis of Nonequivalent Groups: A tutorial for the twang package. R Vignette. RAND. Retrieved from <a href="https://CRAN.R-project.org/package=twang/vignettes/twang.pdf" class="uri">https://CRAN.R-project.org/package=twang/vignettes/twang.pdf</a></p>
<p>Rosenbaum, P. R., &amp; Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41–55. <a href="http://doi.org/10.1093/biomet/70.1.41" class="uri">http://doi.org/10.1093/biomet/70.1.41</a></p>
<p>R Core Team (2016). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
<p>Rubin, D. B. (2001). Using Propensity Scores to Help Design Observational Studies: Application to the Tobacco Litigation. Health Services and Outcomes Research Methodology, 2(3-4), 169–188. <a href="http://doi.org/10.1023/A:1020363010465" class="uri">http://doi.org/10.1023/A:1020363010465</a></p>
<p>Sekhon, J. S. (2011). Multivariate and Propensity Score Matching Software with Automated Balance Optimization: The Matching Package for R. Journal of Statistical Software, 42(7), 1-52. <a href="http://www.jstatsoft.org/v42/i07/" class="uri">http://www.jstatsoft.org/v42/i07/</a>.</p>
<p>Stuart, E. A. (2008). Developing practical recommendations for the use of propensity scores: Discussion of “A critical appraisal of propensity score matching in the medical literature between 1996 and 2003” by Peter Austin, Statistics in Medicine. Statistics in Medicine, 27(12), 2062–2065. <a href="http://doi.org/10.1002/sim.3207" class="uri">http://doi.org/10.1002/sim.3207</a></p>
<p>Stuart, E. A. (2010). Matching Methods for Causal Inference: A Review and a Look Forward. Statistical Science, 25(1), 1–21. <a href="http://doi.org/10.1214/09-STS313" class="uri">http://doi.org/10.1214/09-STS313</a></p>
<p>Stuart, E. A., Lee, B. K., &amp; Leacy, F. P. (2013). Prognostic score-based balance measures can be a useful diagnostic for propensity score methods in comparative effectiveness research. Journal of Clinical Epidemiology, 66(8), S84. <a href="http://dx.doi.org/10.1016/j.jclinepi.2013.01.013" class="uri">http://dx.doi.org/10.1016/j.jclinepi.2013.01.013</a></p>
<p>Thoemmes, F. J., &amp; Kim, E. S. (2011). A Systematic Review of Propensity Score Methods in the Social Sciences. Multivariate Behavioral Research, 46(1), 90–118. <a href="http://doi.org/10.1080/00273171.2011.540475" class="uri">http://doi.org/10.1080/00273171.2011.540475</a></p>
<p>Zhao, Q., &amp; Percival, D. (2015). Primal-dual Covariate Balance and Minimal Double Robustness via Entropy Balancing. arXiv preprint arXiv:1501.03571.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>If none of the examples are working, this may be because <code>MatchIt</code>, <code>twang</code>, or <code>WeightIt</code> is missing. Such issues should be fixed soon.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><code>WeightIt</code> is a wrapper for <code>twang</code>, <code>CBPS</code>, <code>ebal</code>, and other packages for point treatments, so it can perform their functions as well.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Unless common support is used in <code>Matching</code>, in which case the standard deviation is computed using the remaining unadjusted sample.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Standardized mean difference use only unweighted variance estimates; see section “Variance in Standardized Mean Differences” for details.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>In full matching, this is not so straightforward because units are weighted; <code>cobalt</code> differs from <code>MatchIt</code> in that it calculates the effective sample size, consistent with weighting, whereas <code>MatchIt</code> calculates the regular sample size.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Ali et al. (2014) compared the KS statitic to standardized mean differences, but the KS statistic is equivalent to the raw difference in proportion for binary variables.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>This value is a linear function of the other observed values, so it would in principle be able to be computed by the analyst, but it seems more valuable to explicitly include this “redundant calculation” for the sake of ease and completeness.<a href="#fnref7">↩</a></p></li>
</ol>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
